# 级联agent:上游的agent
# 主要是avro sink  其他的source channel 不变

a1.sources = s1
a1.channels = c1
a1.sinks = k1 k2

#  数据在FLume内部以Event的方式传输
#   Event =  Body(数据) + Header(属性)
#
#2  source    TailDir
#  定义source类型
a1.sources.s1.type  = TAILDIR
a1.sources.s1.filegroups = g1 g2 g3
# 采集指定日志文件夹下的数据
a1.sources.s1.filegroups.g1 = /doe/data/applogs/doe_app_events.*
a1.sources.s1.filegroups.g2 = /doe/data/wxlogs/wx.*
a1.sources.s1.filegroups.g3 = /doe/data/weblogs/web.*
# 在不同的日志文件中的Event Header中添加数据类别
a1.sources.s1.headers.g1.logType = app_log
a1.sources.s1.headers.g2.logType = wx_log
a1.sources.s1.headers.g3.logType = web_log
# 修改记录采集数据便宜量文件的位置
a1.sources.s1.positionFile = /opt/flume_data/positions/taildir_position.json

# 一次读取数据行和写入channel的最大数量，通常使用默认值  100
a1.sources.s1.batchSize = 1000

# 配置flume内置的拦截器   host主机拦截器  会在事件的头信息中添加主机信息
a1.sources.s1.interceptors = i1
# 自定义拦截器  抽取日志中的时间
a1.sources.s1.interceptors.i1.type = cn.doitedu.flume.interceptor.ExtractTimeInterceptor$Builder
#  出入的log_dt 作为拦截器中Header的key  put("log_dt" , 解析的日期)
a1.sources.s1.interceptors.i1.x = log_dt
a1.sources.s1.channels = c1

# 使用filechannel  提升采集数据的可靠性 提升数据的安全性  牺牲一定的性能
a1.channels.c1.type = file
# 为了保证数据的安全 引入checkpoint机制  进一步保证采集的数据不会丢失
a1.channels.c1.checkpointDir =/opt/flume_data/checkpoint
# 存储Event数据到指定的文件夹下
a1.channels.c1.dataDirs =/opt/flume_data/data
# channel的最大容量 作为缓存数据的容量 capacity 一定要大于batchSize
a1.channels.c1.capacity = 1000000
# 事务容量  , 处理的事务中 ,所有的总事件之和    capacity  > 事务容量  > batchSize
a1.channels.c1.transactionCapacity =  5000


# 网络sink  可以将Event发送到下游的其他服务器上
a1.sinks.k1.channel = c1
a1.sinks.k1.type = avro
# 将Event发送到的服务器 认识的域名 或者是 ip
a1.sinks.k1.hostname = doitedu02
# 下游服务器的端口  保证doitedu02上有端口号  注意端口号和下游的一致
a1.sinks.k1.port = 8899
# 数据进行压缩传输  ,下游定义压缩接收
a1.sinks.k1.compression-type=deflate
# 压缩权重  值越大压缩比越高  0 代表不压缩
a1.sinks.k1.compression-level = 6

# 网络sink  可以将Event发送到下游的其他服务器上
a1.sinks.k2.channel = c1
a1.sinks.k2.type = avro
# 将Event发送到的服务器 认识的域名 或者是 ip
a1.sinks.k2.hostname = doitedu03
# 下游服务器的端口  保证doitedu02上有端口号  注意端口号和下游的一致
a1.sinks.k2.port = 8899
a1.sinks.k2.compression-type=deflate
a1.sinks.k2.compression-level = 6

# failover组  自动主从切换 实参HA采集
a1.sinkgroups = g1
a1.sinkgroups.g1.sinks = k1 k2
a1.sinkgroups.g1.processor.type = failover
#  权重值大的优先级高  作为主sink
a1.sinkgroups.g1.processor.priority.k1 = 2
# 优先级低  备用sink 当主sink故障 切换工作状态
a1.sinkgroups.g1.processor.priority.k2 = 1
# 重试主sink的间隔时间
a1.sinkgroups.g1.processor.maxpenalty  =30000