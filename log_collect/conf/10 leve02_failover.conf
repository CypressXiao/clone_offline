a1.sources = s1
a1.channels = c1
a1.sinks = k1

a1.sources.s1.type  = avro
# 监听的服务器名hostname或者ip   ; 0.0.0.0接收任意机器发送的数据
a1.sources.s1.bind = 0.0.0.0
# 提供服务的端口
a1.sources.s1.port = 8899

# 配置flume内置的拦截器   host主机拦截器  会在事件的头信息中添加主机信息
a1.sources.s1.interceptors = i1
# 拦截器类型  主机
a1.sources.s1.interceptors.i1.type = host
#  不使用ip作为主机名
a1.sources.s1.interceptors.i1.useIP = false
#  自定义 主机拦截器的头 KEY  默认是host   后续的可以使用  %{hostName}
a1.sources.s1.interceptors.i1.hostHeader = hostName

a1.sources.s1.channels = c1

# 使用filechannel  提升采集数据的可靠性 提升数据的安全性  牺牲一定的性能
a1.channels.c1.type = file
# 为了保证数据的安全 引入checkpoint机制  进一步保证采集的数据不会丢失
a1.channels.c1.checkpointDir =/opt/flume_data/checkpoint
# 存储Event数据到指定的文件夹下
a1.channels.c1.dataDirs =/opt/flume_data/data

# channel的最大容量 作为缓存数据的容量 capacity 一定要大于batchSize
a1.channels.c1.capacity = 1000000
# 事务容量  , 处理的事务中 ,所有的总事件之和    capacity  > 事务容量  > batchSize
a1.channels.c1.transactionCapacity =  5000

#sink        HDFS
a1.sinks.k1.channel = c1
a1.sinks.k1.type = hdfs
# 在sink时 可以获取自定义拦截器中  添加的日志时间学习
a1.sinks.k1.hdfs.path = hdfs://doitedu01:8020/doe/data/%{logType}/%{hostName}/%{log_dt}
# 生成的结果文件可以指定文件的前缀和后缀
a1.sinks.k1.hdfs.filePrefix = doit32_
# 后缀根据文件的类型
a1.sinks.k1.hdfs.fileSuffix = .log
# 向 HDFS 写入内容时每次批量操作的 Event 数量 最好和source端一致
a1.sinks.k1.hdfs.batchSize = 1000

# 默认数据大量的小文件  , 改变输出策略   ,128M滚动一个输出文件
# 默认是30秒滚动生成一个文件  0 禁用时间滚动生成文件
a1.sinks.k1.hdfs.rollInterval = 0
# 默认是1K滚动生成一个文件   128M生成一个文件
a1.sinks.k1.hdfs.rollSize = 134217728
# 默认是10条Event生成一个文件  0 代表禁用以事件个数生成文件的策略
a1.sinks.k1.hdfs.rollCount = 0
#  没有达到文件滚动的时机, 会占用一个临时文件 .tmp ,如果数据长时间的没有生成 , 占用资源 关闭临时文件
#  在指定的时间内 没有采集到新的数据  临时文件会关闭
a1.sinks.k1.hdfs.idleTimeout = 10
# 将数据sink到HDFS可以获取到数据的头信息 , hdfs sink  可以使用当前机器的时间
# a1.sinks.k1.hdfs.useLocalTimeStamp = true