#  使用内置的拦截器 进行开发
#  1 定义一个name为a1的agent  三个组件的别名  分别是 s1  c1  k1
a1.sources = s1
a1.channels = c1
a1.sinks = k1

#  数据在FLume内部以Event的方式传输
#   Event =  Body(数据) + Header(属性)
#
#2  source    TailDir
#  定义source类型
a1.sources.s1.type  = TAILDIR
a1.sources.s1.filegroups = g1 g2 g3
a1.sources.s1.filegroups.g1 = /doe/data/applogs/doe_app_events.log
a1.sources.s1.filegroups.g2 = /doe/data/wxlogs/wx.*
a1.sources.s1.filegroups.g3 = /doe/data/weblogs/web.*
# 在不同的日志文件中的Event Header中添加数据类别
a1.sources.s1.headers.g1.logType = app_log
a1.sources.s1.headers.g2.logType = wx_log
a1.sources.s1.headers.g3.logType = web_log
# 修改记录采集数据便宜量文件的位置
a1.sources.s1.positionFile = /opt/flume_data/positions/taildir_position.json


# 配置flume内置的拦截器   host主机拦截器  会在事件的头信息中添加主机信息
a1.sources.s1.interceptors = i1
# 自定义拦截器  抽取日志中的时间
a1.sources.s1.interceptors.i1.type = myinterceptor
a1.sources.s1.interceptors.i1.x = log_dt

a1.sources.s1.channels = c1
# 获取到Event的Header  [Map]中的数据
#channel    memory
a1.channels.c1.type = memory
#sink        HDFS
a1.sinks.k1.channel = c1
a1.sinks.k1.type = hdfs
# 在sink时 可以获取自定义拦截器中  添加的日志时间学习
a1.sinks.k1.hdfs.path = hdfs://doitedu01:8020/doe/data/%{logType}/%{log_dt}
# 生成的结果文件可以指定文件的前缀和后缀
a1.sinks.k1.hdfs.filePrefix = doit32_
# 后缀根据文件的类型
a1.sinks.k1.hdfs.fileSuffix = .log

# 默认数据大量的小文件  , 改变输出策略   ,128M滚动一个输出文件
# 默认是30秒滚动生成一个文件  0 禁用时间滚动生成文件
a1.sinks.k1.hdfs.rollInterval = 0
# 默认是1K滚动生成一个文件   128M生成一个文件
a1.sinks.k1.hdfs.rollSize = 134217728
# 默认是10条Event生成一个文件  0 代表禁用以事件个数生成文件的策略
a1.sinks.k1.hdfs.rollCount = 0
#  没有达到文件滚动的时机, 会占用一个临时文件 .tmp ,如果数据长时间的没有生成 , 占用资源 关闭临时文件
#  在指定的时间内 没有采集到新的数据  临时文件会关闭
a1.sinks.k1.hdfs.idleTimeout = 10
# 将数据sink到HDFS可以获取到数据的头信息 , hdfs sink  可以使用当前机器的时间
# a1.sinks.k1.hdfs.useLocalTimeStamp = true